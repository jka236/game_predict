{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "# Load the datasets\n",
    "players = pd.read_csv('processed_data/players.csv')\n",
    "games = pd.read_csv('processed_data/games.csv')\n",
    "test = pd.read_csv('processed_data/test.csv')\n",
    "games = pd.read_csv('processed_data/knn_games_df.csv')\n",
    "test = pd.read_csv('processed_data/knn_test_df.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "games['feature'] = [[] for _ in range(len(games))]\n",
    "test['feature'] = [[] for _ in range(len(test))]\n",
    "games['is_home_winner'] = games['home_team_goal'] > games['away_team_goal']\n",
    "player_columns = [f\"home_player_{i}\" for i in range(1, 12)] + [f\"away_player_{i}\" for i in range(1, 12)]    \n",
    "positions = ['GK', 'DEF', 'MID', 'FWD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 66 features\n",
    "def get_player_stats(player_id, year):\n",
    "    # Get the most recent player stats for a given player and year\n",
    "    player_data = players[(players['player_id'] == player_id) & (players['year'] <= year)].sort_values('year', ascending=False).iloc[0]\n",
    "    return player_data[['overall_rating', 'potential', 'crossing']].values\n",
    "\n",
    "def add_player_stats_features(row, features, is_test=False):\n",
    "    year = 2015 if is_test else row['year']\n",
    "    \n",
    "    for player_col in player_columns:\n",
    "        if pd.notna(row[player_col]):\n",
    "            player_stats = get_player_stats(row[player_col], year)\n",
    "            features.extend(player_stats)\n",
    "        else:\n",
    "            features.extend([0, 0, 0])  # Default values for missing players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 4 features\n",
    "def get_team_historical_goal_mean(team_id, year):\n",
    "    # Get the historical average goals scored by a team at home and away games\n",
    "    team_games = games[(games['home_team_id'] == team_id) | (games['away_team_id'] == team_id) & (games['year'] <= year)]\n",
    "    home_goals = team_games[team_games['home_team_id'] == team_id]['home_team_goal'].mean()\n",
    "    away_goals = team_games[team_games['away_team_id'] == team_id]['away_team_goal'].mean()\n",
    "    return np.array([home_goals, away_goals])\n",
    "\n",
    "def add_team_historical_goal_features(row, features, is_test=False):\n",
    "    year = 2015 if is_test else row['year']\n",
    "    \n",
    "    home_team_stats = get_team_historical_goal_mean(row['home_team_id'], year)\n",
    "    away_team_stats = get_team_historical_goal_mean(row['away_team_id'], year)\n",
    "    \n",
    "    features.extend(home_team_stats)\n",
    "    features.extend(away_team_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 8 features\n",
    "positions = ['GK', 'DEF', 'MID', 'FWD']\n",
    "\n",
    "def get_position_ratings(row, team, year):\n",
    "    ratings = {pos: [] for pos in positions}\n",
    "    for i in range(1, 12):\n",
    "        player_id = row[f'{team}_player_{i}']\n",
    "        if pd.notna(player_id):\n",
    "            # Getting the latest player data\n",
    "            player_data = players[(players['player_id'] == player_id) & (players['year'] <= year)].sort_values('year', ascending=False).iloc[0]\n",
    "            position = positions[min(int(row[f'{team}_player_Y{i}']) // 3, 3)]  # Map Y-coordinate to position\n",
    "            ratings[position].append(player_data['overall_rating'])\n",
    "    return {pos: np.mean(r) if r else 0 for pos, r in ratings.items()}\n",
    "\n",
    "\n",
    "def add_position_ratings_features(row, features, is_test=False):\n",
    "    year = 2015 if is_test else row['year']\n",
    "\n",
    "    home_position_stats = get_position_ratings(row, 'home', year)\n",
    "    away_position_stats = get_position_ratings(row, 'away', year)\n",
    "    \n",
    "    for pos in positions:\n",
    "        features.append(home_position_stats[pos])\n",
    "        features.append(away_position_stats[pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding 6 features\n",
    "def get_team_historical_winning_rate(team_id, year, index):\n",
    "    \n",
    "    # Get the historical games\n",
    "    home_games = games[(games['home_team_id'] == team_id) & (games['year'] <= year)]\n",
    "    away_games = games[(games['away_team_id'] == team_id) & (games['year'] <= year)]\n",
    "    \n",
    "    home_games = home_games.drop(index) if index in home_games.index else home_games\n",
    "    away_games = away_games.drop(index) if index in away_games.index else away_games\n",
    "    \n",
    "    # Get all games if no history\n",
    "    if len(home_games) == 0 or len(away_games) == 0:\n",
    "        home_games = games[(games['home_team_id'] == team_id)]\n",
    "        away_games = games[(games['away_team_id'] == team_id)]\n",
    "        \n",
    "    # Use away games for home games if no home games and vice versa\n",
    "    if len(home_games) == 0:\n",
    "        home_games = games[(games['away_team_id'] == team_id)]\n",
    "        \n",
    "    if len(away_games) == 0:\n",
    "        away_games = games[(games['home_team_id'] == team_id)]\n",
    "    \n",
    "    # Default values if no games\n",
    "    if len(home_games) == 0 or len(away_games) == 0:\n",
    "        return np.array([0.5, 0.5, 0.5])    \n",
    "    \n",
    "    home_games_winning = home_games[home_games['is_home_winner'] == True]\n",
    "    away_games_winning = away_games[away_games['is_home_winner'] == False]\n",
    "        \n",
    "    home_games_winning_rate = len(home_games_winning) / len(home_games)\n",
    "    away_games_winning_rate = len(away_games_winning) / len(away_games)\n",
    "    \n",
    "    total_winning_rate = (len(home_games_winning) + len(away_games_winning)) / (len(home_games) + len(away_games))\n",
    "    \n",
    "    return np.array([home_games_winning_rate, away_games_winning_rate, total_winning_rate])\n",
    "\n",
    "def add_team_historical_winning_rate_features(row, features, is_test=False):\n",
    "    year = 2015 if is_test else row['year']\n",
    "    \n",
    "    home_team_winning_rate = get_team_historical_winning_rate(row['home_team_id'], year, row.name)    \n",
    "    away_team_winning_rate = get_team_historical_winning_rate(row['away_team_id'], year, row.name)\n",
    "    \n",
    "    features.extend(home_team_winning_rate)\n",
    "    features.extend(away_team_winning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head_to_head_winning_rate(team1_id, team2_id, year, index):\n",
    "    h2h_games = games[\n",
    "        (((games['home_team_id'] == team1_id) & (games['away_team_id'] == team2_id)) |\n",
    "         ((games['home_team_id'] == team2_id) & (games['away_team_id'] == team1_id))) &\n",
    "        (games['year'] <= year ) \n",
    "        ]\n",
    "    \n",
    "    if h2h_games.empty:\n",
    "        h2h_games = games[\n",
    "        (((games['home_team_id'] == team1_id) & (games['away_team_id'] == team2_id)) |\n",
    "         ((games['home_team_id'] == team2_id) & (games['away_team_id'] == team1_id)))\n",
    "        ]\n",
    "    \n",
    "    h2h_games = h2h_games.drop(index) if index in h2h_games.index else h2h_games\n",
    "    \n",
    "    team1_wins = ((h2h_games['home_team_id'] == team1_id) & (h2h_games['is_home_winner'] == True)).sum() + \\\n",
    "                 ((h2h_games['away_team_id'] == team1_id) & (h2h_games['is_home_winner'] == False)).sum()\n",
    "    \n",
    "    total_games = len(h2h_games)\n",
    "    \n",
    "    return [team1_wins / total_games if total_games > 0 else 0.5]\n",
    "\n",
    "def add_head_to_head_winning_rate_features(row, features, is_test=False):\n",
    "    year = 2015 if is_test else row['year']\n",
    "    \n",
    "    h2h_winning_rate = get_head_to_head_winning_rate(row['home_team_id'], row['away_team_id'], year, row.name)\n",
    "    features.extend(h2h_winning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(row, features, is_test=False):\n",
    "    add_player_stats_features(row, features, is_test)\n",
    "    add_team_historical_goal_features(row, features, is_test)\n",
    "    add_position_ratings_features(row, features, is_test)\n",
    "    add_team_historical_winning_rate_features(row, features, is_test)\n",
    "    add_head_to_head_winning_rate_features(row, features, is_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To be used to add only one feature\n",
    "# games['tmp_feature'] = [[] for _ in range(len(games))]\n",
    "# test['tmp_feature'] = [[] for _ in range(len(test))]\n",
    "# adding_feature = add_head_to_head_winning_rate_features\n",
    "\n",
    "# games.apply(lambda row: adding_feature(row, row['tmp_feature']), axis=1)\n",
    "# test.apply(lambda row: adding_feature(row, row['tmp_feature'], is_test=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Combine 'tmp_feature' and 'feature' columns\n",
    "# games['feature'] = games.apply(lambda row: row['feature'] + row['tmp_feature'], axis=1)\n",
    "# test['feature'] = test.apply(lambda row: row['feature'] + row['tmp_feature'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      None\n",
       "1      None\n",
       "2      None\n",
       "3      None\n",
       "4      None\n",
       "       ... \n",
       "995    None\n",
       "996    None\n",
       "997    None\n",
       "998    None\n",
       "999    None\n",
       "Length: 1000, dtype: object"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.apply(lambda row: create_features(row, row['feature']), axis=1)\n",
    "test.apply(lambda row: create_features(row, row['feature'], is_test=True), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to csv and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# games.to_csv(os.path.join(\"processed_data\", \"games_feature.csv\"), index=False)\n",
    "# test.to_csv(os.path.join(\"processed_data\", \"test_feature.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def string_to_numpy(string_repr):\n",
    "#     cleaned_string = string_repr.replace('np.float64(', '').replace(')', '')\n",
    "#     numpy_list = np.fromstring(cleaned_string[1:-1], sep=',')\n",
    "#     return numpy_list\n",
    "\n",
    "\n",
    "# games = pd.read_csv('processed_data/games_feature.csv')\n",
    "# games['feature'] = games['feature'].apply(string_to_numpy)\n",
    "\n",
    "# test = pd.read_csv('processed_data/test_feature.csv')\n",
    "# test['feature'] = test['feature'].apply(string_to_numpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(games['feature'].values)\n",
    "X_to_predict = np.vstack(test['feature'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a model for winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation rmse: 0.4537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import ensemble\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "games['is_home_winner'] = games['home_team_goal'] > games['away_team_goal']\n",
    "y = games['is_home_winner'].values\n",
    "\n",
    "# Split the training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the GradientBoostingRegressor\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "winner_boosting_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values by filling with the mean\n",
    "    # ('imputer', KNNImputer(n_neighbors=1)), # Marginally better than SimpleImputer (0.0001)\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', ensemble.GradientBoostingRegressor(**params))\n",
    "])\n",
    "\n",
    "winner_boosting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "val_predictions = winner_boosting_pipeline.predict(X_val)\n",
    "rmse = root_mean_squared_error(y_val, val_predictions)\n",
    "print(f\"Validation rmse: {rmse:.4f}\")\n",
    "# Validation rmse: 0.4567"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning score predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation rmse: 1.1574\n"
     ]
    }
   ],
   "source": [
    "# Set y value\n",
    "games['goal_diff'] = (games['home_team_goal'] - games['away_team_goal']).abs()\n",
    "y = games['goal_diff'].values\n",
    "\n",
    "# Split the training data\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the GradientBoostingRegressor\n",
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "win_by_boosting_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values by filling with the mean\n",
    "    # ('imputer', KNNImputer(n_neighbors=1)), # Did not improve the model\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', ensemble.GradientBoostingRegressor(**params))\n",
    "])\n",
    "\n",
    "win_by_boosting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error\n",
    "val_predictions = win_by_boosting_pipeline.predict(X_val)\n",
    "rmse = root_mean_squared_error(y_val, val_predictions)\n",
    "print(f\"Validation rmse: {rmse:.4f}\")\n",
    "# Validation rmse: 1.1635"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with all data\n",
    "games['is_home_winner'] = games['home_team_goal'] > games['away_team_goal']\n",
    "y = games['is_home_winner'].values\n",
    "winner_boosting_pipeline.fit(X, y)\n",
    "\n",
    "games['goal_diff'] = (games['home_team_goal'] - games['away_team_goal']).abs()\n",
    "y = games['goal_diff'].values\n",
    "win_by_boosting_pipeline.fit(X, y)\n",
    "\n",
    "winner = winner_boosting_pipeline.predict(X_to_predict)\n",
    "winby = win_by_boosting_pipeline.predict(X_to_predict)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'winner': winner,\n",
    "    'winby': winby\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('processed_data/predictions_with_feature_engineer.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict with KNN test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_test = pd.read_csv('processed_data/knn_test_df.csv')\n",
    "knn_test['feature'] = [[] for _ in range(len(test))]\n",
    "knn_test.apply(lambda row: create_features(row, row['feature'], is_test=True), axis=1)\n",
    "X_knn_to_predict = np.vstack(knn_test['feature'].values)\n",
    "\n",
    "winner = winner_boosting_pipeline.predict(X_knn_to_predict)\n",
    "winby = win_by_boosting_pipeline.predict(X_knn_to_predict)\n",
    "\n",
    "predictions_df = pd.DataFrame({\n",
    "    'winner': winner,\n",
    "    'winby': winby\n",
    "})\n",
    "\n",
    "predictions_df.to_csv('processed_data/predictions_with_feature_engineer_knn_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
